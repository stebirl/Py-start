{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stebirl/Py-start/blob/main/Tag_3_Datens%C3%A4tze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 08-27-GS-2 - Einführung in die Datenverarbeitung und -visualisierung mit Python\n",
        "\n",
        "5-tägiger Blockkurs - Stella Birlo\n"
      ],
      "metadata": {
        "id": "QjINJL3uvfY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------\n",
        "# Tag 3 - Datensätze"
      ],
      "metadata": {
        "id": "DwbCu9uc4IHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Datentypen und Datensätze"
      ],
      "metadata": {
        "id": "LaG4jwv04fjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es gibt viele andere Datentypen, die in der Datenanalyse und -verarbeitung vorkommen können. Hier sind einige Beispiele:\n",
        "\n",
        "* **Numerische Daten**: Dies sind Daten, die Zahlenwerte darstellen, wie zum Beispiel die Größe oder das Gewicht von Objekten, die Temperatur oder der Druck in einem System.\n",
        "\n",
        "* **Kategorische Daten**: Diese Art von Daten repräsentiert eine feste Anzahl von Kategorien oder Labels, wie zum Beispiel die Farbe von Objekten, der Hersteller eines Produkts oder die Kategorie von Produkten in einem Online-Shop.\n",
        "\n",
        "* **Textdaten**: Dies sind Daten, die aus Text bestehen, wie zum Beispiel die Beschreibung von Produkten, Kundenfeedback oder soziale Medien Beiträge.\n",
        "\n",
        "* Bild- und Videodaten: Diese Art von Daten besteht aus Pixeln oder Bildpunkten, die ein Bild oder Video darstellen. Sie werden häufig in der Bildverarbeitung, Gesichtserkennung und Überwachung eingesetzt.\n",
        "\n",
        "* **Geodaten**: Dies sind Daten, die geographische Informationen enthalten, wie zum Beispiel Längen- und Breitengrade von Standorten, Karten- und Satellitenbilder oder Geo-Tags von Fotos.\n",
        "\n",
        "* Graphdaten: Dies sind Daten, die aus Knoten und Kanten bestehen und Beziehungen zwischen Objekten oder Entitäten darstellen, wie zum Beispiel in sozialen Netzwerken, Empfehlungssystemen oder Netzwerkarchitekturen.\n",
        "\n",
        "* Audio-Daten: Diese Datentypen repräsentieren Schallwellen und werden in der Spracherkennung, Musikanalyse und anderen Audioanwendungen verwendet.\n",
        "\n",
        "* Binärdaten: Dies sind Daten, die in Binärform vorliegen, wie zum Beispiel Dateien, die in Computern gespeichert sind. Sie können Text, Bilder, ausführbare Programme und mehr repräsentieren.\n",
        "\n",
        "* **Bool'sche Daten** (Boolesche Werte): Dies sind Daten, die nur zwei mögliche Werte annehmen können, oft wahr (true) oder falsch (false). Sie werden häufig in bedingten Aussagen und Logikoperationen verwendet.\n",
        "\n",
        "* Komplexe Zahlen: In der Mathematik repräsentieren komplexe Zahlen Werte mit einem Realteil und einem Imaginärteil. Sie werden in verschiedenen Bereichen der Ingenieurwissenschaften und der Physik verwendet.\n",
        "\n",
        "* **NULL oder NaN:** Diese repräsentieren oft den Mangel an Daten oder eine undefinierte oder nicht zutreffende Zustandsinformation.\n",
        "\n",
        "* UUID (Universally Unique Identifier): Ein eindeutiger Identifikator, der oft in Datenbanken und verteilten Systemen verwendet wird.\n",
        "\n",
        "* **JSON **(JavaScript Object Notation): Ein Datenformat, das oft für den Austausch strukturierter Informationen zwischen einem Server und einem Webbrowser verwendet wird.\n",
        "\n",
        "* XML (Extensible Markup Language): Ein weiteres Format für den Austausch strukturierter Informationen, häufig in der Webentwicklung und Datenübertragung verwendet.\n",
        "\n",
        "* Tensor: In der maschinellen Lern- und neuronalen Netzwerktechnik repräsentiert ein Tensor eine mehrdimensionale Datenstruktur, die in diesem Kontext für das Speichern und Verarbeiten von Daten verwendet wird.\n",
        "\n",
        "* **Datenframes**: In der Datenanalyse, insbesondere mit Bibliotheken wie Pandas in Python, repräsentieren Datenframes tabellenartige Datenstrukturen mit Zeilen und Spalten, ähnlich wie in Datenbanktabellen.\n",
        "\n",
        "* Byte-Arrays: Eine sequenzielle Anordnung von Bytes, die in der Programmierung für die Arbeit mit Binärdaten verwendet wird."
      ],
      "metadata": {
        "id": "mA2SwFMiPFdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Einzelne Daten werden zu Datensätzen zusammengefasst.\n",
        "\n",
        "Dabei werden Messungen/Personen/... immer in Zeilen (rows/index) und die verschiedenen Messgrößen in Spalten (columns) angezeigt.\n",
        "\n",
        "Excel ist ein handliches Werkzeug um kleinere Datensätze zu untersuchen. Bei größeren Datensätzen ist es allerdings handlicher, diese mit Tools wie Python zu analysieren."
      ],
      "metadata": {
        "id": "MwvsNorebDpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Neues Paket: Pandas - Grundlagen der Datenmanipulation in Python\n",
        "\n",
        "Pandas ist eine leistungsstarke Bibliothek für Datenmanipulation und -analyse in Python.\n",
        "Mit Pandas können wir sogenannte \"Dataframes\" erstellen, vergleichbar mit einer Excel-Tabelle.\n",
        "\n",
        "Hier ein Cheatsheet dazu: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
        "\n",
        "Bevor wir beginnen, stellt sicher, dass Pandas installiert ist. Falls nicht, kannst du es mit dem folgenden Befehl installieren (nicht nötig in Colab):"
      ],
      "metadata": {
        "id": "m_WLfQyqW5Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "ZD2K0nXuXIBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrames erstellen\n",
        "# ... aus einer Liste\n",
        "import pandas as pd\n",
        "\n",
        "data = [['Alice', 25], ['Bob', 30], ['Charlie', 35]]\n",
        "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
        "df\n",
        "\n",
        "# Resultat: eine Tabelle mit Zwei Spalten (columns) und drei Zeilen (index)"
      ],
      "metadata": {
        "id": "dv8LaF4PXLHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... aus einem dictionary\n",
        "import numpy as np\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie',\"Marie\",\"Frank\",\"Horst\"],\n",
        "        'Age': [30, 30, 35, 54, 89, 51],\n",
        "        'Salary': [50000, 60000, 45000, np.nan, 47000, 30000]}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "j5b8CBxnXj3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() # nur die ersten 5 Zeilen anzeigen lassen"
      ],
      "metadata": {
        "id": "g505aH7PecrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generelle Infos über Datendatz\n",
        "\n",
        "print(df.info())\n",
        "#print(df.dtypes)\n",
        "#print(df.describe())"
      ],
      "metadata": {
        "id": "6cqsL_HuXr-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing & slicing\n",
        "df[2:4]           # rows-index\n",
        "df.iloc[2:4,1:]   # .iloc = index location - [rows,columns]\n",
        "df[\"Age\"]         # column name\n",
        "df.loc[3:,\"Age\"]  # .loc = aufruf über Name - [row name, column name]"
      ],
      "metadata": {
        "id": "USN4_mLO3Uc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsets\n",
        "df[df.Age >= 50]\n",
        "df[(df.Age >= 50) & (df.Salary <= 50000)]\n",
        "f = df.loc[df[\"Age\"] >= 50, [\"Name\"]]         # Ergebnis als pandas DF\n",
        "df.Name[df[\"Age\"] >= 50]                      # Ergebnis als pandas Series"
      ],
      "metadata": {
        "id": "8NL5dvmu4wWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# einfache Berechnungen\n",
        "df.Age.mean()      # Mittelwert\n",
        "#df.Salary.max()    # Maximum\n",
        "#df.Name.count()    # Anzahl\n",
        "#df.Salary.count()  # Anzahl\n",
        "#df.Salary.std()    # Standardabweichung\n",
        "\n",
        "#..."
      ],
      "metadata": {
        "id": "P8zW66Rw5iC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neue Spalte hinzufügen\n",
        "df[\"Holidays\"] = [30,25,54,21,35,23]\n",
        "df\n",
        "\n",
        "# Neuen Eintrag/Person einfügen\n",
        "df = df.append({\"Name\":\"Caren\",\"Age\":62,\"Salary\":75000,\"Holidays\":60}, ignore_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "OKhqYD6p5pdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach NaNs suchen und Werte ändern\n",
        "# NaN = Not a Number\n",
        "df.isnull()\n",
        "df.Salary.isnull()\n",
        "df[df.Salary.isnull()]\n",
        "\n",
        "df.loc[3,\"Salary\"] = 70000\n",
        "df"
      ],
      "metadata": {
        "id": "aqIML-mnqwRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index ändern\n",
        "df2 = df.copy()\n",
        "df2 = df2.set_index(\"Name\")\n",
        "df2\n",
        "#df2.loc[\"Bob\",\"Salary\"]\n",
        "#df2.iloc[1,1]"
      ],
      "metadata": {
        "id": "S2kwuWyt415-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "df2_t = df2.T\n",
        "df2_t"
      ],
      "metadata": {
        "id": "20CjEl6GDoJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeitreihen-Datensatz erstellen\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime    # Kleine Erklärunge zu \"datetime\" am Ende des Skripts\n",
        "\n",
        "start_date = datetime(2023, 1, 1) # Jahr, Monat, Tag\n",
        "end_date = datetime(2023, 12, 31)\n",
        "date_range = pd.date_range(start=start_date, end=end_date, freq='D' ) # D = Täglich, M = Monatlich, Y = Jährlich, h = stündlich,...\n",
        "time_series_data = np.random.rand(len(date_range))                    # np.random.rand() generiert Zufallszahlen in einer bestimmten Form\n",
        "print(date_range[:10], time_series_data[:10])"
      ],
      "metadata": {
        "id": "Gy6H1-vKVN7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series_df = pd.DataFrame({'Date': date_range, 'Value': time_series_data})\n",
        "time_series_df"
      ],
      "metadata": {
        "id": "oopq8JlN0m_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kategorische Daten\n",
        "categories = ['Category A', 'Category B', 'Category C', 'Category D']\n",
        "num_samples = 100\n",
        "\n",
        "categorical_df = pd.DataFrame({'Category': np.random.choice(categories, num_samples),\n",
        "                                  'Value': np.random.rand(num_samples).round(1),\n",
        "                                'Value2': np.random.rand(num_samples).round(1)})\n",
        "categorical_df\n",
        "\n",
        "#grouped_data = categorical_df.groupby('Category').agg({'Value': [\"count\",'mean',\"min\",\"max\"],'Value2': ['mean',\"min\",\"max\"]})\n",
        "#grouped_data"
      ],
      "metadata": {
        "id": "MBEauznHWRqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapefiles (Geo-Daten)\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Erstelle Punkte für Städte\n",
        "cities = {'City': ['Berlin', 'Paris', 'New York', 'Tokyo'],\n",
        "          'Latitude': [52.5200, 48.8566, 40.7128, 35.6895],\n",
        "          'Longitude': [13.4050, 2.3522, -74.0060, 139.6917]}\n",
        "\n",
        "cities_df = pd.DataFrame( cities)\n",
        "geometry = [Point(xy) for xy in zip(cities_df['Longitude'], cities_df['Latitude'])]\n",
        "# Eine weitere Art strings zu formulieren\n",
        "# zip verschmelzt mehrere Dinge\n",
        "# Point würde in ArcGIS ein Punkt-Shape erstellen\n",
        "geo_data = gpd.GeoDataFrame(cities_df, geometry=geometry, crs='EPSG:4326') # Projektions auswählen\n",
        "geo_data"
      ],
      "metadata": {
        "id": "V2p2Y6mgWju_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zusammenfassung\n",
        "* Mit dem Paket Pandas können wir Excel-ähnliche Listen erstellen\n",
        "* Diese nennt man in der Programmierumgebung \"Dataframes\"\n",
        "* Dataframes können unterschiedliche Datentypen enthalten\n",
        "* über .loc und .iloc kann ich auf die einzelnen Inhalte filtern\n",
        "* Filtern geht so: [Zeilen, Spalten]\n",
        "* Es gibt eine vielzahl von Funktionen, die dafür da sind die DFs auf unterschiedliche Aspekte zu überprüfen ->https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html"
      ],
      "metadata": {
        "id": "LIIvpT-rwFen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Übung 3.1.\n",
        "\n",
        "1. Erstelle ein DF aus den vorgegebenen Daten\n",
        "2. Wähle nur die Spalte 'Name' aus dem Datenrahmen aus.\n",
        "3. Filtere die Zeilen, in denen das Alter größer als 25 ist.\n",
        "4. Füge eine neue Spalte 'Department' hinzu, die die Werte 'HR', 'IT', 'Marketing', 'Finance','HR', 'IT', 'Marketing', 'Finance','IT' für die entsprechenden Personen enthält.\n",
        "5. Aktualisiere das Gehalt von Alice auf 65000.\n",
        "6. Gruppiere Nach \"Department\", gebe die Anzahl (und die einzelen Namen) der Mitarbeiter sowie das durchschnittliche Gehalt aus"
      ],
      "metadata": {
        "id": "sroBt0yb7GMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', \"Franz\" , \"Lisbeth\", \"Caro\", \"Darius\", \"Idris\"],\n",
        "        'Age': [25, 30, 22, 35, 65, 80, 45, 26, 48 ],\n",
        "        'Salary': [50000, 60000, 45000, 70000,94000,66500,66200,23000,42000]}\n"
      ],
      "metadata": {
        "id": "s49DPG1q3MD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Datenanalyse Verlauf"
      ],
      "metadata": {
        "id": "ZeREFhI-fIvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Datensätze können als unterschiedliches Dateiformat vorliegen:\n",
        "  * .xlsx/.xls (Excel-Dateiformat): Binäres Dateiformat für Microsoft Excel.\n",
        "    * Vorteile: Unterstützt mehrere Tabellenblätter.\n",
        "        Speichert Formatierungen, Formeln und Diagramme.\n",
        "        Wird von vielen Tabellenkalkulationsprogrammen unterstützt.\n",
        "    * Nachteile:\n",
        "        Nicht einfach als Textdatei lesbar.\n",
        "        Größere Dateigröße im Vergleich zu .csv.\n",
        "\n",
        "  * .csv (Comma-Separated Values):Textbasiertes Dateiformat, bei dem Daten durch Kommata getrennt sind.\n",
        "    * Vorteile:\n",
        "        Einfaches Textformat, leicht lesbar und editierbar.\n",
        "        Kompakt in der Größe.\n",
        "        Weit verbreitet und von vielen Anwendungen unterstützt.\n",
        "    * Nachteile:\n",
        "        Begrenzte Unterstützung für komplexe Datentypen.\n",
        "        Keine Möglichkeit zur Speicherung von Formatierungen oder Mehrfachblättern.\n",
        "\n",
        "  * .txt (Textdatei): Einfache Textdatei, die nur Textdaten enthält.\n",
        "    * Vorteile:\n",
        "        Plattformunabhängig und einfach lesbar.\n",
        "        Unterstützt von nahezu allen Texteditoren und Programmiersprachen.\n",
        "    * Nachteile:\n",
        "        Keine Strukturierung von Daten, es sei denn, sie wird manuell definiert.\n",
        "        Nicht für komplexe Datensätze geeignet.\n",
        "\n",
        "  * ... und viele mehr\n",
        "\n",
        "- Plattformunabhängigkeit: .csv und .txt sind plattformunabhängig und können von verschiedenen Systemen gelesen werden.\n",
        "- Lesbarkeit: .xlsx-Dateien können aufgrund ihres binären Formats schwer lesbar sein, während .csv und .txt menschenlesbar sind.\n",
        "- Datenstruktur: .xlsx ermöglicht die Strukturierung von Daten in verschiedenen Blättern, während .csv und .txt einfache lineare Datensätze sind.\n",
        "- Anwendungsbereich: .xlsx eignet sich gut für komplexe Tabellenkalkulationen, während .csv und .txt für den Austausch einfacher Datensätze verwendet werden können.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sSuE1LG_f8xB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Daten import\n",
        "Datensätze zu importieren kann anfangs etwas Zeit kosten, manchmal sogar die längste Zeit einer Analyse. Schaut euch vorher immer die Datei genauer an, die ihr imporieren wollt.\n",
        "\n",
        "Pandas können wir auch benutzen, um Datensätze zu importieren, bzw. exportieren.\n",
        "\n",
        "Lade die Beispieldatensätze für Tag 3 herunter und packe diese in einen eigenen Ordner (z.B. \"Beispieldatensätze\")\n",
        "\n",
        "Schauen wir uns die Daten erst Mal an"
      ],
      "metadata": {
        "id": "RM05uo4LiBL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l-wKf8S_WnE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wenn du mir Google Colab arbeitest:\n",
        "# Drive muss verbunden werden\n",
        "#Reference: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveAå\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WqjSbMWvavPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel-Datein\n",
        "\n",
        "# Colab: Navigiere über die Leiste Link bist zur Datei und kopiere den Pfad\n",
        "# Local: Kopiere den Datei-Pfad und ersetze die Zeile \"path\"\n",
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Python_Kurs/Beispieldatensätze/'\n",
        "df = pd.read_excel(path+\"Beispiel_Excel.xlsx\")\n",
        "df\n",
        "\n",
        "# HINWEIS: Falls du local arbeitest könnte es sein, dass hinter \"path\" noch \", engine=\"openpyxl\"\" folgen muss"
      ],
      "metadata": {
        "id": "f9ChFdV4XsVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excel-Datein 2\n",
        "\n",
        "# Erstes Datenblatt wird automatisch importiert\n",
        "# Aber jetzt möchten wir das zweite Datenblatt importieren\n",
        "# sheet_name=\"\"\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Python_Kurs/Beispieldatensätze/'\n",
        "df2 = pd.read_excel(path+\"Beispiel_Excel.xlsx\", sheet_name=\"Sheet2\")\n",
        "df2"
      ],
      "metadata": {
        "id": "KzuZ5h9_XsMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comma Seperated files\n",
        "df3 = pd.read_csv(path+\"Beispiel_CSV1.csv\")\n",
        "df3"
      ],
      "metadata": {
        "id": "zIhhDoV5XsAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comma Seperated files 2\n",
        "df4 = pd.read_csv(path+\"Beispiel_CSV2.csv\")\n",
        "df4\n",
        "# was ist falsch? Auch erkennabr, bei Sichtungüber Editor\n",
        "# Semikolon statt Komma\n"
      ],
      "metadata": {
        "id": "ksu051RkXrfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comma Seperated files 2\n",
        "df4 = pd.read_csv(path+\"Beispiel_CSV2.csv\", sep=\";\")\n",
        "df4\n",
        "# was ist falsch? Auch erkennabr, bei Sichtungüber Editor\n",
        "# Semikolon statt Komma"
      ],
      "metadata": {
        "id": "V5pXCWTJZyjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text files\n",
        "\n",
        "df5 = pd.read_csv(path+\"Beispiel_TXT.txt\", sep=\";\")\n",
        "df5\n",
        "# was ist falsch? Auch erkennabr, bei Sichtungüber Editor\n",
        "# Tabs zwischen den Values und Kopfzeilen erst in der dritten Zeile"
      ],
      "metadata": {
        "id": "xlLC_OfdX4Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text files\n",
        "\n",
        "df5 = pd.read_csv(path+\"Beispiel_TXT.txt\", sep=\"\\t\", header= 2)\n",
        "df5\n",
        "\n",
        "# Tabs zwischen den Values und Kopfzeilen erst in der dritten Zeile"
      ],
      "metadata": {
        "id": "uwMjgXecaZwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beispiel Movies\n",
        "Movies Datensatz von:\n",
        "\n",
        "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. https://doi.org/10.1145/2827872\n",
        "\n",
        "1. Dateien findet ihr auf: https://grouplens.org/datasets/movielens/\n",
        "\n",
        "2. Download der ml-latest-small.zip (unter: recommended for education and development)\n",
        "\n",
        "3. Entpacken und in den Ordner \"Beispieldatensätze\" hinzufügen\n",
        "\n",
        "4. README Datein anschauen"
      ],
      "metadata": {
        "id": "PT0KM0JsWvzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wenn du mir Google Colab arbeitest\n",
        "# Drive muss verbunden werden\n",
        "#Reference: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveAå\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TUCnveWvsGm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## .csv importieren\n",
        "import pandas as pd\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Python_Kurs/Beispieldatensätze/'\n",
        "df_movie = pd.read_csv(path+\"movies.csv\")\n",
        "df_movie"
      ],
      "metadata": {
        "id": "mHYjJSBPMGB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rating = pd.read_csv(path+\"ratings.csv\")\n",
        "df_rating"
      ],
      "metadata": {
        "id": "e30utng0bwaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rating = pd.read_csv(path+\"ratings.csv\")\n",
        "df_rating"
      ],
      "metadata": {
        "id": "YaUumhAcb098"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tag = pd.read_csv(path+\"tags.csv\")\n",
        "df_tag"
      ],
      "metadata": {
        "id": "zyqGXlHpMF8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Daten sichten & bearbeiten\n",
        " Jetzt haben wir 3 DataFrames importiert\n",
        "\n",
        " Jetzt wollen wir aus df_movie und df_rating ein DF machen um die Filmnamen direkt neben den Bewertungen zu haben\n",
        "\n",
        " Schauen wir uns dafür erst mal df_movie genauer an"
      ],
      "metadata": {
        "id": "XKDgfD_jawst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing & slicing\n",
        "df_movie.head()\n",
        "#df_movie.info()\n",
        "#df_movie.dtypes\n",
        "#df_movie[:10] # bezieht sich nur auf Zeilen/rows/index\n",
        "#df_movie.iloc[5:10,:2] # iloc = index location, bezieht isch auf [Zeilen, Columns]\n",
        "#df_movie.loc[:10,\"title\"] # .loc = location, bezieht sich auf [Zeilen, column_name]\n",
        "#df_movie.loc[[1,3,5],[\"movieId\",\"title\"]]\n"
      ],
      "metadata": {
        "id": "xY0BoITBbWDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rating.head()\n",
        "#df_rating.dtypes\n",
        "#df_rating[\"movieId\"].unique()\n",
        "#df_rating[df_rating[\"movieId\"] == 306]\n",
        "#df_movie[df_movie[\"movieId\"] == 306]\n",
        "#df_rating[df_rating[\"userId\"] == 25]\n",
        "#df_rating[\"rating\"][df_rating[\"userId\"] == 25]\n",
        "#df_rating[\"rating\"][df_rating[\"userId\"] == 25].mean()"
      ],
      "metadata": {
        "id": "pllY0m-Qp9x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datensätze zusammenfügen\n",
        "# merge\n",
        "# https://realpython.com/pandas-merge-join-and-concat/\n",
        "# auch im Cheat-sheet beschrieben\n",
        "\n",
        "DF = pd.merge(df_movie, df_rating, how=\"left\", on=\"movieId\")  # \"how\" = wir wollen die rechte Df auf die linke übertragen\n",
        "DF                                                            # basierend auf \"movieId\""
      ],
      "metadata": {
        "id": "-pRAfkCZp9um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daten nach Usern sortieren\n",
        "DF.sort_values(by=\"userId\")\n",
        "\n",
        "# Daten nach Filmen ohne ratings durchsuchen\n",
        "#DF[DF.rating.isnull()]  # Nach Leeren Zeilen suchen (Gegenteil wäre .notnull())\n",
        "#DF = DF.dropna().copy() # Unbewertete Filme aus der Liste löschen\n",
        "\n",
        "#DF[DF.duplicated()]     # Nach Duplikaten suchen\n",
        "DF"
      ],
      "metadata": {
        "id": "rTkXMxZ9yhP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_DF = DF.groupby(\"title\").agg({\"rating\":\"mean\",\"userId\":\"count\"})\n",
        "grouped_DF\n",
        "\n",
        "#grouped_DF = grouped_DF.sort_values(\"rating\", ascending=False)\n",
        "#grouped_DF\n",
        "# beste Filme mit vielen Bewertungen?\n",
        "#grouped_DF[(grouped_DF.rating>=4) & (grouped_DF.userId >= 150)]"
      ],
      "metadata": {
        "id": "CbLpD88sBU-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nach Pulp Fiction suchen\n",
        "pulp_df = DF[DF[\"title\"].str.contains(\"Pulp Fiction\")]\n",
        "pulp_df\n",
        "\n",
        "# Welche Bewertung hat Pulp Fiction im durchschnitt bekommen?\n",
        "#print(\"Pulp Fiction Bewertung ist:\",pulp_df.rating.mean().round(2))\n",
        "\n",
        "# Nur 4.2?? Wer hat den Film bitte schlechter als 3 Sterne gegeben?\n",
        "#pulp_df[pulp_df.rating <= 3]\n",
        "\n",
        "# Idioten! Die haben keine Ahnung. Die Idioten-User wollen wir auf den DF rausschneiden\n",
        "#idiot_list = pulp_df.userId[pulp_df.rating <= 3].to_list()            # Alle User identifiezien\n",
        "#print(\"Die ersten 5 Idioten sind:\", idiot_list[:5])\n",
        "\n",
        "#idiot_idx = DF.index[DF.userId.isin(idiot_list)]                     # Alle indices (Reihennummern) mit diesen Usern raussuchen\n",
        "#print(\"die ersten 5 Indices der idioten sind:\",idiot_idx[:5])\n",
        "\n",
        "#no_idiots_DF = DF.drop(index = idiot_idx).copy()                      # indices der idioten löschen\n",
        "\n",
        "#Idioten wirklich raus?\n",
        "#print(\"Länge DF vorher:\",len(DF),\" -- Länge DF nachher:\",len(no_idiots_DF))\n",
        "#no_idiots_DF[:10]\n",
        "#no_idiots_DF[no_idiots_DF.userId == idiot_list[0]]\n",
        "\n",
        "# Welche Bewertung hat Pulp Fiction jetzt?\n",
        "#new_rating = no_idiots_DF.rating[no_idiots_DF[\"title\"].str.contains(\"Pulp Fiction\")].mean()\n",
        "#print(\"Die neue Pulp Fiction Bewertung ist:\", round(new_rating,2))"
      ],
      "metadata": {
        "id": "Txaxl_GE4R37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Übung 3.2.\n",
        "\n",
        "Hinweise zu dieser Übung gibt es am Ende des Skripts.\n",
        "Versucht es aber erst Mal ohne, nutzt z.B. die Funktions-Hilfe oder Google\n",
        "\n",
        "1. Erstelle ein DF2, in dem df_tag dem DF Datensatz hinzugefügt wird, gruppiere nach \"movieId\".\n",
        "\n",
        "2. In der \"tag\" Spalte gibt es jetzt viele NaNs, da nicht jeder User jeden Film getagged hat. Lösche diese Zeilen.\n",
        "\n",
        "3. Finde alle Filme die mit \"Alien\" getagged sind. Beachte auch, dass unterschiedliche Schreibweisen vorkommen (Groß/Klein, Einzahl/Mehrzahl, Wortteil)\n",
        "\n",
        "4. Filtere nur die am besten bewerteten (>=4.5) Alien-Filme. Erstelle eine Liste mit den Film Namen, nenne die Liste \"best_alien_list\"\n",
        "\n",
        "5. Nutze die neue Liste um alle Bewertungen für diese besten Alien-Filme anzeigen zu lassen. Mache daraus ein DF (Name: best_alien_df).\n",
        "\n",
        "6. Kannst du die Mittelwerte für jede Filmbewertung berechnen? Und wie viele Bewertungen es pro Film gibt? Welcher ist der Beste Alien Film mit über 150 Bewertungen? (Name: best_alien_grouped_df)"
      ],
      "metadata": {
        "id": "Amq4Jw2X79yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframes & Loops"
      ],
      "metadata": {
        "id": "x1DUSL81BMtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe aus Loop erstellen\n",
        "Alien = []\n",
        "for i,x in enumerate(best_alien_list):\n",
        "  print(i,x)\n",
        "  #Mean = DF2.rating[(DF2.title == x)].mean()\n",
        "  #Anzahl =  len(DF2[(DF2.title == x)])\n",
        "  #Anzahl5 = len(DF2[(DF2.title == x) & (DF2.rating == 5)])\n",
        "  #print(Mean, Anzahl, Anzahl5)\n",
        "  #Alien.append({\"Movie\": x,\"Mittlere Bewertung\": Mean,\"Anzahl Bewertungen\": Anzahl, \"Anzahl 5*\": Anzahl5})\n",
        "\n",
        "#df_best_alien = pd.DataFrame(Alien)\n",
        "#df_best_alien[\"% 5 Sterne\"] = round((df_best_alien[\"Anzahl 5*\"]/df_best_alien[\"Anzahl Bewertungen\"])*100,2)\n",
        "#df_best_alien"
      ],
      "metadata": {
        "id": "W471aSLJBPsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop durch DataFrames\n",
        "import numpy as np\n",
        "df_best_alien[\"% 5\"] = np.nan\n",
        "df_best_alien\n",
        "#for i in df_best_alien.index:\n",
        "#  df_best_alien.loc[i,\"% 5\"] = round((df_best_alien.loc[i,\"Anzahl 5*\"]/df_best_alien.loc[i,\"Anzahl Bewertungen\"])*100,2)\n",
        "#df_best_alien"
      ],
      "metadata": {
        "id": "rH5UH--SaEg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df_best_alien[:10].index:\n",
        "  for j in df_best_alien[:10].columns:\n",
        "    print(i,j, df_best_alien.loc[i,j])\n"
      ],
      "metadata": {
        "id": "l9a3jublbLW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Daten export"
      ],
      "metadata": {
        "id": "VpvFiTFzvb2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "id": "C6ABEtA3cIws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DF2 exporieren\n",
        "\n",
        "df_best_alien.to_excel(path+\"df_best_alien.xlsx\")\n",
        "\n",
        "# oder\n",
        "\n",
        "df_best_alien.to_csv(path+\"df_best_alien.csv\",index=False)"
      ],
      "metadata": {
        "id": "SoXz92isp9nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Freie Übung\n",
        "Benutze folgende Seite als Hilfe: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n"
      ],
      "metadata": {
        "id": "Ph6JzdLL4zMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "pd.set_option('display.max_columns', None) # Um sich alle columns anzeigen zu lassen\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[*range(0,26)])\n",
        "df"
      ],
      "metadata": {
        "id": "FD88v-TNxDD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Stelle selbst Fragen an den Datensatz und versuche sie zu beantworten. Evtl. musst du nach einigen Funktionen googlen\n",
        "\n",
        "Diese Fragen könnten z.B. sein:\n",
        "  * Welche Marken sind in dieser Liste?\n",
        "  * Welche Marke hat den höchsten Preis?\n",
        "  * Was ist die row bzw. column number der Zelle mit dem höchsten Preis ?(Hinweis: np.where()-funktion, .was können .iat[] oder .at[] Funktionen?, .get_value())\n",
        "  * Gibt es fehlende Einträge?\n",
        "  * Wie kann ich eine Spalte hinzufügen die Marke und Modellname vereint?\n",
        "  * ..."
      ],
      "metadata": {
        "id": "5ZRm6utqgb2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Für nicht-Auto-Experten wie mich:\n",
        "  \n",
        "    Model: Der Modellname des Autos.\n",
        "    Type: Der Typ des Autos (z.B., Limousine, Kombi, etc.).\n",
        "    Min.Price: Der minimale Preis des Autos.\n",
        "    Price: Der Preis des Autos.\n",
        "    Max.Price: Der maximale Preis des Autos.\n",
        "    MPG.city: Der Kraftstoffverbrauch in Meilen pro Gallone in der Stadt.\n",
        "    MPG.highway: Der Kraftstoffverbrauch in Meilen pro Gallone auf der Autobahn.\n",
        "    AirBags: Informationen über die Airbag-Ausstattung des Autos.\n",
        "    DriveTrain: Der Antrieb des Autos (z.B., Vorderradantrieb, Hinterradantrieb).\n",
        "    Cylinders: Die Anzahl der Zylinder im Motor.\n",
        "    EngineSize: Die Größe des Motors.\n",
        "    Horsepower: Die Pferdestärken des Motors.\n",
        "    RPM: Die Umdrehungen pro Minute des Motors.\n",
        "    Rev.per.mile: Die Motorumdrehungen pro Meile.\n",
        "    Man.trans.avail: Die Verfügbarkeit eines manuellen Getriebes.\n",
        "    Fuel.tank.capacity: Die Tankkapazität des Autos.\n",
        "    Passengers: Die Anzahl der Passagiere, die das Auto aufnehmen kann.\n",
        "    Length: Die Länge des Autos.\n",
        "    Wheelbase: Der Radstand des Autos.\n",
        "    Width: Die Breite des Autos.\n",
        "    Turn.circle: Der Wendekreis des Autos.\n",
        "    Rear.seat.room: Der Platz im hinteren Sitzbereich.\n",
        "    Luggage.room: Der Stauraum im Kofferraum.\n",
        "    Weight: Das Gewicht des Autos.\n",
        "    Origin: Die Herkunft des Autos."
      ],
      "metadata": {
        "id": "iG-bqHPsV-X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stöbere selbst auf der Seite etwas rum und versuche ein paar Dinge umzusetzen:\n",
        "https://www.machinelearningplus.com/python/101-pandas-exercises-python/"
      ],
      "metadata": {
        "id": "ZlJIif1gigpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zusatz: 3.4. Exkurs datetime"
      ],
      "metadata": {
        "id": "DI4T8qDJjnWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeitreihen erstellen\n",
        "# Datetime\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "print(\"Aktuelles Datum und Uhrzeit:\", now)"
      ],
      "metadata": {
        "id": "LXvigJfDzEGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year = now.year\n",
        "month = now.month\n",
        "day = now.day\n",
        "hour = now.hour\n",
        "minute = now.minute\n",
        "second = now.second\n",
        "\n",
        "print(\"Jahr:\", year)\n",
        "print(\"Monat:\", month)\n",
        "print(\"Tag:\", day)\n",
        "print(\"Stunde:\", hour)\n",
        "print(\"Minute:\", minute)\n",
        "print(\"Sekunde:\", second)"
      ],
      "metadata": {
        "id": "GUsUcXiFzkao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mit Strings formatieren\n",
        "formatted_date = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(\"Formatiertes Datum:\", formatted_date)\n",
        "\n",
        "# oder z.B.:\n",
        "formatted_date = now.strftime(\"%Y-%d-%m: %H Uhr\")\n",
        "print(\"Formatiertes Datum:\", formatted_date)"
      ],
      "metadata": {
        "id": "lIxqvL-Rztm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hinweise für Übung 3.2.: (probiert es erst Mal ohne, viele Wege führen nach Rom)\n",
        "\n",
        "1. merge()\n",
        "2. notnull(), dropna()\n",
        "3. isin & \"Alien\",\"alien\",\"Aliens\",\"aliens\" oder: .str.contains(..., regex=?, case=?)\n",
        "4. [(...) & (...)], unique() & tolist()\n",
        "5. .isin()\n",
        "6. .groupby & .agg\n"
      ],
      "metadata": {
        "id": "mjPlOR9qWWzH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7dv-HlYdWXlA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}